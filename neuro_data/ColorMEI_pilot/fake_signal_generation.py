import datajoint as dj
dj.config['external'] = dict(protocol='file',
                              location='/external/')

import numpy as np
import matplotlib.pyplot as plt
from scipy import signal
from featurevis.ops import GaussianBlur
from neuro_data.static_images.data_schemas import *
import pandas as pd 

from staticnet_experiments.models import Model
from neuro_data.static_images.data_schemas import StaticMultiDataset

from staticnet_experiments.configs import NetworkConfig, TrainConfig, ReadoutConfig, ShifterConfig, DataConfig, CoreConfig, ModulatorConfig
from staticnet_experiments.models import Model
neurodata_static = dj.create_virtual_module('neurodata_static', 'neurodata_static')
import h5py

from .dj_parent import DJTableBase
import json


def add_noise(img, mean, var):
    """
    Add gaussian white noise to the image
    
    input:
        img (numpy array): N dimensional image in shape of ch, row, col
        mean (float): mean value for the guassian noise to be centered at
        var (float): variance value for the guassian noise. 
    
    return:
        noisy_img (numpy array): N dimensional image in shape of ch, row, col after noise added
    
    """
    ch, row, col = img.shape
    sigma = var**0.5
    gauss = np.random.normal(mean, sigma, (ch,row,col))
    
    return img + gauss


#TODO change noise_hash to param_id
@schema
class GaussianNoise(dj.Lookup, DJTableBase):
    definition = """
    # Parameters for Gaussian noise
    noise_hash      : char(32)              # MD5 in base64
    ---
    mean            : float                 # mean value for the gaussian noise to be centered at
    var             : float                 # variance value for the gaussian noise
    """

    @classmethod
    def fill(cls, mean, var):
        noise_hash = cls.generate_md5_hash(dict(mean=mean,var=var))
        cls.insert1([noise_hash, mean, var])

#TODO reflect hash to param id in fill method
@schema
class NoisyGaussianKernels(dj.Manual, DJTableBase):
    definition = """
    # Gaussian kernels with noise added. Katrin generated the kernels
    kernel_hash   : char(32)              # MD5 in base64
    ---
    noise_type          : varchar(128)          # noise type name
    noise_params        : varchar(256)          # dictionary containing noise params
    kernels       : external             # noisy gaussian rfs
    """
    
    @staticmethod
    def fill(path_to_gaussian_rf_file, noise_params):
        """
        path_to_gaussian_rf_file (str): absolute path for gaussian_rf_file
        """

        # katrin's gaussian RF generation
        filename = path_to_gaussian_rf_file

        with h5py.File(filename, 'r') as f:
            # List all groups
            print("Keys: %s" % f.keys())
            a_group_key = list(f.keys())[0]

            # Get the data
            data = list(f[a_group_key])

        gaussian_rfs = np.array(data).transpose(3,2,0,1)

        # obtain noise table and its params
        noise_table = eval(noise_params['noise_type'])

        # Until finding a better way to restrict with floats, Lookup the noise table first,
        # then restrict by the hash.
        mean_val, var_val = (noise_table & "noise_hash ='{}'".format(noise_params['noise_hash'])).fetch1('mean','var')

        kernels = np.zeros(shape=gaussian_rfs.shape)
        new_noise_params = dict(mean=mean_val, var=var_val)

        kernel_hash = DJTableBase.generate_md5_hash(dict(new_noise_params,
                                                               noise_type=noise_params['noise_type']))
        
        # add noise to the kernel and insert
        for ind,rf in enumerate(gaussian_rfs):
            kernels[ind,:,:,:]=add_noise(img=rf, mean = mean_val, var=var_val)
        
        NoisyGaussianKernels.insert1(dict(kernel_hash=kernel_hash,
                                          noise_type=noise_params['noise_type'],
                                          noise_params=json.dumps(new_noise_params),
                                          kernels=kernels.transpose(0,2,3,1)))


"""
animal_id       : smallint unsigned     # animal_id
scan_idx        : smallint unsigned     # scan_idx
session         : smallint unsigned     # session number
"""

@schema
class FakeResponseFromImages(dj.Manual, DJTableBase):
    definition = """
    # fake signals generated by convolving input images with kernels
    ->stimulus.Trial
    response_hash       : char(32)              # MD5 in base64
    ---
    input_image_class    : varchar(128)          # stimulus image class
    kernel_type         : varchar(128)          # kernel type
    kernel_hash         : char(32)              # MD5 in base64
    response            : external              # averaged fake response
    """

    @staticmethod
    def fill(key, kernel_params):
        
        # find the key's stimulus type and its table, then fetch image data
        stim_type = np.unique((stimulus.Condition & (stimulus.Trial & key)).fetch('stimulus_type'))

        if len(stim_type) > 1:
            raise ValueError("There must be only 1 stimulus type! Currently there are stimuli of : {}".format(stim_type))
        else:
            stim_type = stim_type[0].split('.')[1]
        stim_table = getattr(stimulus, stim_type)

        id_table = ((stimulus.Trial & key) * stim_table).proj('image_id','channel_1','channel_2','channel_3')
        img_table = (stimulus.StaticImage.Image & 'image_class = "imagenet_v2_rgb"') & id_table

        image_class, images = (id_table * img_table).fetch('image_class','image')
        image_class = np.unique(image_class)

        if len(image_class) > 1:
            raise ValueError("There must be only 1 image class! Currently there are : {} classes".format(image_class))
        else:
            image_class = image_class[0]

        # find which colors were used for imagenet images
        colors = np.array((id_table & 'trial_idx = 0').fetch1('channel_1','channel_2','channel_3'))
        
        valid_colors =(colors[colors != None] - 1).astype('int')

        # obtain the kernels
        kernel_table = eval(kernel_params['kernel_type']) & 'kernel_hash = "{}"'.format(kernel_params['kernel_hash'])
        kernels = kernel_table.fetch1('kernels')

        # number of neurons = number of kernels
        num_neurons = kernels.shape[0]

        # generate fake values
        response_block = np.zeros(shape=(len(images),len(kernels)))

        for img_ind, img in enumerate(images):
            print(img_ind)
            #TODO color_ind logic can be improved. For now, hardcoded for kernel channel config
            restricted_img = np.zeros(shape=kernels.shape[1:])
            
            for channel_ind, color_ind in enumerate(valid_colors):
                restricted_img[:,:,channel_ind] = img[:,:,color_ind]  
            
            convolved = np.multiply(restricted_img, kernels)
            
            # introduce nonlinearity
            convolved[convolved<0] = 0 

            signals = convolved.reshape(num_neurons,-1).mean(-1)
                
            response_block[img_ind,:] = signals

    
        return response_block

                

        